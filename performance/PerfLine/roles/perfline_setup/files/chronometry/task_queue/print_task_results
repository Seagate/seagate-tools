#!/usr/bin/env python3
#
# Copyright (c) 2020 Seagate Technology LLC and/or its Affiliates
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# For any questions about this software or licensing,
# please email opensource@seagate.com or cortx-questions@seagate.com.
#


import json
import sys
import re
from prettytable import PrettyTable
import os
from collections import namedtuple

ROUNDING_PRECISION = 4 # number of digit after decimal point
SUM_COLUMN = 'sum' # name of column
S3BENCH_LOG_NAME_PATTERN = '^s3bench-(?P<hostname>.*).log$'

# 'name' is optional. It is used for convert original field name to a shorter
# 'sum' option is used to mark fields which should be summed from all nodes
# 'aggr' option is used to mark fields which should be printed in summary table
FIELDS = {'numClients' : {'name' : "nCli", 'opts' : ['aggr']},
          'numSamples' : {'name' : "nSamp", 'opts' : ['aggr']},
          'objectSize (MB)' : {'name' : 'obj_s MB', 'opts' : ['aggr']},
          'Total Throughput (MB/s)' : {'name' : 'Thr', 'opts' : ['aggr', 'sum']},
          'Total Transferred (MB)' : {'name' : 'Size', 'opts' : ['sum']},
          'Ttfb 99th-ile' : {'name' : 'ttfb-99'},
          'Ttfb 90th-ile' : {'name' : 'ttfb-90'},
          'Ttfb Max' : {'name' : 'ttfb-max'},
          'Ttfb Min' : {'name' : 'ttfb-min'},
          'Ttfb Avg' : {'name' : 'ttfb-avg'},
          'Total Duration (s)' : {'name' : 'duration'},
          'Total Requests Count' : {'name' : 'request_nr', 'opts' : ['sum'] },
          'Errors Count' : {'name' : 'errors', 'opts' : ['sum']}
          }

run_result_list = list()

def is_s3bench_log(file_path):
    path_parts = file_path.split('/')
    p = re.compile(S3BENCH_LOG_NAME_PATTERN)
    return p.match(path_parts[-1]) != None

def parse_hostname(file_path):
    path_parts = file_path.split('/')
    p = re.compile(S3BENCH_LOG_NAME_PATTERN)
    match_res = p.match(path_parts[-1])
    return match_res.group('hostname')

def parse_s3bench_log(file_path):
    print(file_path)
    with open(file_path) as f:
        data = json.loads(f.read())
    return data

def get_visible_field_name(raw_field_name):
    field_desc = FIELDS[raw_field_name]
    if 'name' in field_desc:
        return field_desc['name']
    else:
        return raw_field_name

Measurement = namedtuple('Measurement' , 'measurement_name operation')

class run_results:
    def __init__(self, task_id):
        self.task_id = task_id
        self.params = dict()
        self.measurements = dict()
        self._hostnames = list()

    def get_s3bench_params(self):
        result = dict()
        for param_name, param_values in self.params.items():
            shared_param_value = None
            for cli_hostname, val in param_values.items():

                # skip aggregated values (such as 'sum')
                if cli_hostname not in self._hostnames:
                    continue

                if shared_param_value is None:
                    shared_param_value = val
                elif shared_param_value != val:
                    raise Exception("Found different s3bench parameters during the test run")

            result[param_name] = shared_param_value
        return result

    def put_data(self, cli_hostname, raw_data):
        self._hostnames.append(cli_hostname)
        self._put_params(cli_hostname, raw_data)
        self._put_measurements(cli_hostname, raw_data)

    def _put_params(self, cli_hostname, raw_data):
        for k, v in raw_data['Parameters'].items():
            if k in FIELDS:
                if k not in self.params:
                    self.params[k] = dict()

                row = self.params[k]
                row[cli_hostname] = v

    def _put_measurements(self, cli_hostname, raw_data):
        for test_results in raw_data['Tests']:
            operation_name = test_results['Operation']

            print(operation_name)
            if operation_name == 'Read':
                operation_name = 'R'
            elif operation_name == 'Write':
                operation_name = 'W'
            elif operation_name == 'PutObjTag':
                operation_name = 'P'
            elif operation_name == 'GetObjTag':
                operation_name = 'G'
            elif operation_name == 'HeadObj':
                operation_name = 'H'
            else:
                raise Exception("unexpected operation name")

            for measure_name, measure_val in test_results.items():
                if measure_name in FIELDS:
                    measurement = Measurement(measure_name, operation_name)
                    if measurement not in self.measurements:
                        self.measurements[measurement] = dict()

                    row = self.measurements[measurement]
                    row[cli_hostname] = measure_val

                    if field_required_calc_sum(measure_name):
                        if SUM_COLUMN not in row:
                            row[SUM_COLUMN] = 0
                        row[SUM_COLUMN] += measure_val

def cut_task_id(task_id):
    return "{0}***{1}".format(task_id[0:4], task_id[-4:])

def field_has_option(field_name, opt_name):
    field_desc = FIELDS[field_name]

    if 'opts' in field_desc:
        return opt_name in field_desc['opts']
    else:
        return False

def is_field_for_aggr_table(field_name):
    return field_has_option(field_name, 'aggr')

def field_required_calc_sum(field_name):
    return field_has_option(field_name, 'sum')

class ui_summary_table:
    def __init__(self):
        self._header = ["task_id"]
        self._rows = list()

    def add_data(self, data):
        row_data = {"task_id" : cut_task_id(data.task_id)}
        self._rows.append(row_data)

        for param_name, param_val in data.get_s3bench_params().items():
            visible_param_name = get_visible_field_name(param_name)
            if visible_param_name not in self._header:
                self._header.append(visible_param_name)

            row_data[visible_param_name] = param_val

        for result_name, result_vals in data.measurements.items():

            if not is_field_for_aggr_table(result_name.measurement_name):
                continue

            for cli_hostname, val in result_vals.items():
                column_name = "{0}({1})({2})".format(
                    get_visible_field_name(result_name.measurement_name),
                    result_name.operation, cli_hostname)

                if column_name not in self._header:
                    self._header.append(column_name)

                row_data[column_name] = round(val, ROUNDING_PRECISION)

    def print(self):
        pt = PrettyTable(self._header)

        for row_data in self._rows:
            row_for_print = list()

            for column_name in self._header:
                if column_name in row_data:
                    row_for_print.append(row_data[column_name])
                else:
                    row_for_print.append("X")

            pt.add_row(row_for_print)

        print(pt)


class ui_table:
    def __init__(self, run_results_data):
        self._run_results = run_results_data

    def print(self):

        self.table_head = []
        for hostname in self._run_results._hostnames:
            self.table_head.append(hostname)

        self.table_head.append(SUM_COLUMN)
        first_column_name = "parameters/results"
        head_for_print = [first_column_name]
        head_for_print.extend(self.table_head)
        pt = PrettyTable(head_for_print)
        pt.align[first_column_name] = 'l'
        self._create_rows(pt, self._run_results.params, False)
        self._create_rows(pt, self._run_results.measurements, True)
        print(pt)

    def _create_rows(self, ptable, data, is_measurement):
        for row_key, row_data in data.items():

            if is_measurement:
                row_name = "{0}({1})".format(
                    get_visible_field_name(row_key.measurement_name),
                    row_key.operation)
            else:
                row_name = get_visible_field_name(row_key)

            row = [row_name]
            for column in self.table_head:
                if column in row_data:
                    row.append(round(row_data[column], ROUNDING_PRECISION))
                else:
                    row.append('')
            ptable.add_row(row)


def find_s3bench_logs(path_to_artifacts_dir):
    s3bench_dirs = dict()
    for item in os.walk(path_to_artifacts_dir):
        all_files = item[2]
        s3bench_files = list(filter(is_s3bench_log, all_files))
        if len(s3bench_files) > 0:
            dir_path = item[0]

            # transform each file_name to file_path
            s3bench_files = list(map(lambda f: "{0}/{1}".format(dir_path, f),
                                            s3bench_files))
            s3bench_dirs[dir_path] = s3bench_files
    return s3bench_dirs


def process_run_results(s3bench_log_list, task_id):
    dt = run_results(task_id)

    # processing data from several s3bench log files
    # related to the same test run
    for s3bench_log in s3bench_log_list:
        cli_hostname = parse_hostname(s3bench_log)
        data_from_file = parse_s3bench_log(s3bench_log)
        dt.put_data(cli_hostname, data_from_file)

    # saving for summary table
    run_result_list.append(dt)

    # printing of run details table
    detail_table = ui_table(dt)
    detail_table.print()

if __name__ == '__main__':
    for line in sys.stdin:
        task_data = json.loads(line)
        task_id = task_data[0]['task_id']
        path_to_artifacts = task_data[2]['info']['artifacts_dir']
        print('\ntask {0}'.format(task_id))

        # find s3bench logs and group them by test runs
        s3bench_dirs = find_s3bench_logs(path_to_artifacts)

        for s3bench_logs in s3bench_dirs.values():
            process_run_results(s3bench_logs, task_id)

    # printing the summary table
    aggr_t = ui_summary_table()
    for dt in run_result_list:
        aggr_t.add_data(dt)
    aggr_t.print()
